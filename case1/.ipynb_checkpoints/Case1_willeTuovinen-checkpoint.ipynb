{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case 1 Heart Disease Classification, model nro.2\n",
    "Wille Tuovinen and Eemil Rantanen, \n",
    "4.2.2019, \n",
    "Helsinki Metropolia University of Applied Sciences\n",
    " \n",
    "# Reason why we are building this Neural Network\n",
    "Objective of this document was to lear usage of librarys and building a Neural Network. Goal was allso to lear and test bifferent model architecture's and visualize outputs with matplotlib. \n",
    "Here we tried another way to create NN, but our end-output isn't quite accurate/clear to us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________________________________________________________________________________________________________________________\n",
    "___________________________________________________________________________________________________________________________\n",
    "\n",
    "### Importing required librarys and data. \n",
    "Pandas DataFrame gives massive functionality to work on data thus, here we are using pandas to import data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calling required libraries\n",
    "import numpy as np\n",
    "import time\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
    "from keras.utils import to_categorical\n",
    "from keras import models, layers\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import confusion_matrix\n",
    "clasifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>treshbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>68.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>277.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>64.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>76.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>62.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>281.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>298.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>68.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>58.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>67.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>54.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>239.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>59.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>288.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>46.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>243.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>44.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>44.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>57.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>57.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>51.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>41.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>64.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>54.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>283.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>59.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>53.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>41.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>57.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>57.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>289.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>46.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>58.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>49.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>46.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>57.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>47.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>60.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>58.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>71.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>57.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>55.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>289.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>59.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>39.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>62.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>45.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>42.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>46.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>249.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>58.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>330.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>53.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>62.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>57.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>325.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  sex   cp  treshbps   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "id                                                                            \n",
       "293  63.0  1.0  4.0     140.0  187.0  0.0      2.0    144.0    1.0      4.0   \n",
       "159  68.0  1.0  3.0     118.0  277.0  0.0      0.0    151.0    0.0      1.0   \n",
       "20   64.0  1.0  1.0     110.0  211.0  0.0      2.0    144.0    1.0      1.8   \n",
       "257  76.0  0.0  3.0     140.0  197.0  0.0      1.0    116.0    0.0      1.1   \n",
       "137  62.0  1.0  2.0     120.0  281.0  0.0      2.0    103.0    0.0      1.4   \n",
       "150  52.0  1.0  1.0     152.0  298.0  1.0      0.0    178.0    0.0      1.2   \n",
       "176  52.0  1.0  4.0     108.0  233.0  1.0      0.0    147.0    0.0      0.1   \n",
       "266  52.0  1.0  4.0     128.0  204.0  1.0      0.0    156.0    1.0      1.0   \n",
       "299  68.0  1.0  4.0     144.0  193.0  1.0      0.0    141.0    0.0      3.4   \n",
       "45   58.0  1.0  3.0     112.0  230.0  0.0      2.0    165.0    0.0      2.5   \n",
       "256  67.0  0.0  4.0     106.0  223.0  0.0      0.0    142.0    0.0      0.3   \n",
       "17   54.0  1.0  4.0     140.0  239.0  0.0      0.0    160.0    0.0      1.2   \n",
       "141  59.0  1.0  1.0     170.0  288.0  0.0      2.0    159.0    0.0      0.2   \n",
       "217  46.0  0.0  4.0     138.0  243.0  0.0      2.0    152.0    1.0      0.0   \n",
       "142  52.0  1.0  2.0     128.0  205.0  1.0      0.0    184.0    0.0      0.0   \n",
       "260  44.0  0.0  3.0     118.0  242.0  0.0      0.0    149.0    0.0      0.3   \n",
       "93   44.0  0.0  3.0     108.0  141.0  0.0      0.0    175.0    0.0      0.6   \n",
       "10   57.0  1.0  4.0     140.0  192.0  0.0      0.0    148.0    0.0      0.4   \n",
       "202  57.0  1.0  3.0     150.0  126.0  1.0      0.0    173.0    0.0      0.2   \n",
       "139  51.0  1.0  3.0     125.0  245.0  1.0      2.0    166.0    0.0      2.4   \n",
       "295  41.0  1.0  2.0     120.0  157.0  0.0      0.0    182.0    0.0      0.0   \n",
       "302  38.0  1.0  3.0     138.0  175.0  0.0      0.0    173.0    0.0      0.0   \n",
       "154  64.0  1.0  4.0     120.0  246.0  0.0      2.0     96.0    1.0      2.2   \n",
       "102  57.0  0.0  4.0     128.0  303.0  0.0      2.0    159.0    0.0      0.0   \n",
       "188  54.0  1.0  2.0     192.0  283.0  0.0      2.0    195.0    0.0      0.0   \n",
       "106  59.0  1.0  4.0     140.0  177.0  0.0      0.0    162.0    1.0      0.0   \n",
       "179  53.0  1.0  3.0     130.0  246.0  1.0      2.0    173.0    0.0      0.0   \n",
       "212  41.0  1.0  3.0     130.0  214.0  0.0      2.0    168.0    0.0      2.0   \n",
       "15   57.0  1.0  3.0     150.0  168.0  0.0      0.0    174.0    0.0      1.6   \n",
       "98   52.0  1.0  2.0     134.0  201.0  0.0      0.0    158.0    0.0      0.8   \n",
       "..    ...  ...  ...       ...    ...  ...      ...      ...    ...      ...   \n",
       "146  57.0  1.0  4.0     165.0  289.0  1.0      2.0    124.0    0.0      1.0   \n",
       "69   46.0  1.0  3.0     150.0  231.0  0.0      0.0    147.0    0.0      3.6   \n",
       "144  58.0  1.0  3.0     105.0  240.0  0.0      2.0    154.0    1.0      0.6   \n",
       "232  49.0  1.0  3.0     118.0  149.0  0.0      2.0    126.0    0.0      0.8   \n",
       "272  46.0  1.0  4.0     140.0  311.0  0.0      0.0    120.0    1.0      1.8   \n",
       "248  52.0  1.0  4.0     125.0  212.0  0.0      0.0    168.0    0.0      1.0   \n",
       "259  57.0  1.0  2.0     124.0  261.0  0.0      0.0    141.0    0.0      0.3   \n",
       "281  47.0  1.0  3.0     130.0  253.0  0.0      0.0    179.0    0.0      0.0   \n",
       "66   60.0  1.0  3.0     140.0  185.0  0.0      2.0    155.0    0.0      3.0   \n",
       "210  37.0  0.0  3.0     120.0  215.0  0.0      0.0    170.0    0.0      0.0   \n",
       "251  58.0  1.0  4.0     146.0  218.0  0.0      0.0    105.0    0.0      2.0   \n",
       "273  71.0  0.0  4.0     112.0  149.0  0.0      0.0    125.0    0.0      1.6   \n",
       "211  38.0  1.0  1.0     120.0  231.0  0.0      0.0    182.0    1.0      3.8   \n",
       "37   57.0  1.0  4.0     150.0  276.0  0.0      2.0    112.0    1.0      0.6   \n",
       "153  55.0  1.0  4.0     160.0  289.0  0.0      2.0    145.0    1.0      0.8   \n",
       "274  59.0  1.0  1.0     134.0  204.0  0.0      0.0    162.0    0.0      0.8   \n",
       "242  49.0  0.0  4.0     130.0  269.0  0.0      0.0    163.0    0.0      0.0   \n",
       "109  39.0  1.0  4.0     118.0  219.0  0.0      0.0    140.0    0.0      1.2   \n",
       "92   62.0  1.0  3.0     130.0  231.0  0.0      0.0    146.0    0.0      1.8   \n",
       "100  45.0  1.0  4.0     115.0  260.0  0.0      2.0    185.0    0.0      0.0   \n",
       "186  42.0  1.0  3.0     120.0  240.0  1.0      0.0    194.0    0.0      0.8   \n",
       "237  46.0  1.0  4.0     120.0  249.0  0.0      2.0    144.0    0.0      0.8   \n",
       "62   58.0  1.0  4.0     128.0  216.0  0.0      2.0    131.0    1.0      2.2   \n",
       "118  63.0  1.0  4.0     130.0  330.0  1.0      2.0    132.0    1.0      1.8   \n",
       "283  35.0  1.0  2.0     122.0  192.0  0.0      0.0    174.0    0.0      0.0   \n",
       "87   53.0  0.0  3.0     128.0  216.0  0.0      2.0    115.0    0.0      0.0   \n",
       "72   62.0  1.0  4.0     120.0  267.0  0.0      0.0     99.0    1.0      1.8   \n",
       "300  57.0  1.0  4.0     130.0  131.0  0.0      0.0    115.0    1.0      1.2   \n",
       "290  67.0  1.0  3.0     152.0  212.0  0.0      2.0    150.0    0.0      0.8   \n",
       "84   52.0  1.0  2.0     120.0  325.0  0.0      0.0    172.0    0.0      0.2   \n",
       "\n",
       "     slope   ca thal  num  \n",
       "id                         \n",
       "293    1.0  2.0  7.0  2.0  \n",
       "159    1.0  1.0  7.0  1.0  \n",
       "20     2.0  0.0  3.0  1.0  \n",
       "257    2.0  0.0  3.0  1.0  \n",
       "137    2.0  1.0  7.0  2.0  \n",
       "150    2.0  0.0  7.0  1.0  \n",
       "176    1.0  3.0  7.0  1.0  \n",
       "266    2.0  0.0    0  2.0  \n",
       "299    2.0  2.0  7.0  2.0  \n",
       "45     2.0  1.0  7.0  2.0  \n",
       "256    1.0  2.0  3.0  1.0  \n",
       "17     1.0  0.0  3.0  1.0  \n",
       "141    2.0  0.0  7.0  2.0  \n",
       "217    2.0  0.0  3.0  1.0  \n",
       "142    1.0  0.0  3.0  1.0  \n",
       "260    2.0  1.0  3.0  1.0  \n",
       "93     2.0  0.0  3.0  1.0  \n",
       "10     2.0  0.0  6.0  1.0  \n",
       "202    1.0  1.0  7.0  1.0  \n",
       "139    2.0  0.0  3.0  1.0  \n",
       "295    1.0  0.0  3.0  1.0  \n",
       "302    1.0    0  3.0  1.0  \n",
       "154    3.0  1.0  3.0  2.0  \n",
       "102    1.0  1.0  3.0  1.0  \n",
       "188    1.0  1.0  7.0  2.0  \n",
       "106    1.0  1.0  7.0  2.0  \n",
       "179    1.0  3.0  3.0  1.0  \n",
       "212    2.0  0.0  3.0  1.0  \n",
       "15     1.0  0.0  3.0  1.0  \n",
       "98     1.0  1.0  3.0  1.0  \n",
       "..     ...  ...  ...  ...  \n",
       "146    2.0  3.0  7.0  2.0  \n",
       "69     2.0  0.0  3.0  2.0  \n",
       "144    2.0  0.0  7.0  1.0  \n",
       "232    1.0  3.0  3.0  2.0  \n",
       "272    2.0  2.0  7.0  2.0  \n",
       "248    1.0  2.0  7.0  2.0  \n",
       "259    1.0  0.0  7.0  2.0  \n",
       "281    1.0  0.0  3.0  1.0  \n",
       "66     2.0  0.0  3.0  2.0  \n",
       "210    1.0  0.0  3.0  1.0  \n",
       "251    2.0  1.0  7.0  2.0  \n",
       "273    2.0  0.0  3.0  1.0  \n",
       "211    2.0  0.0  7.0  2.0  \n",
       "37     2.0  1.0  6.0  2.0  \n",
       "153    2.0  1.0  7.0  2.0  \n",
       "274    1.0  2.0  3.0  2.0  \n",
       "242    1.0  0.0  3.0  1.0  \n",
       "109    2.0  0.0  7.0  2.0  \n",
       "92     2.0  3.0  7.0  1.0  \n",
       "100    1.0  0.0  3.0  1.0  \n",
       "186    3.0  0.0  7.0  1.0  \n",
       "237    1.0  0.0  7.0  2.0  \n",
       "62     2.0  3.0  7.0  2.0  \n",
       "118    1.0  3.0  7.0  2.0  \n",
       "283    1.0  0.0  3.0  1.0  \n",
       "87     1.0  0.0    0  1.0  \n",
       "72     2.0  2.0  7.0  2.0  \n",
       "300    2.0  1.0  7.0  2.0  \n",
       "290    2.0  0.0  7.0  2.0  \n",
       "84     1.0  0.0  3.0  1.0  \n",
       "\n",
       "[303 rows x 14 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = 'https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data'\n",
    "df = pd.read_csv(data, sep=',' , header = None)\n",
    "\n",
    "# Let's convert some missplaysed \"?\" strings to lets say, to 0, with this awfull \"monster\" of a code.\n",
    "df = df.fillna(df.median())\n",
    "df = df.fillna(0.0)\n",
    "df = df.replace(\"?\", 0.0)\n",
    "\n",
    "# naming columns\n",
    "df.columns = [\"age\", \"sex\", \"cp\", \"treshbps\", \"chol\", \"fbs\", \"restecg\", \"thalach\",\n",
    "              \"exang\", \"oldpeak\", \"slope\", \"ca\", \"thal\", \"num\"]\n",
    "\n",
    "# here we change values higher that 0.0 to 2.0, and values equal to  0.0, to 1.0\n",
    "df.loc[df.num > 0.0, 'num'] = 2.0\n",
    "df.loc[df.num <= 0.0, 'num'] = 1.0\n",
    "\n",
    "# rename axis\n",
    "df.index.name = 'id'   \n",
    "\n",
    "df['num'] = pd.to_numeric(df['num']).astype(float)\n",
    "\n",
    "# Randomize rows\n",
    "df = shuffle(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we generate .csv from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Case1.2_.csv')\n",
    "\n",
    "#If you look at the CSV there, you should see it has the headers. \n",
    "#df.to_csv('Case1.2_wille.csv', header=False)\n",
    "\n",
    "# Or you whatn to save file as HTML\n",
    "#df.to_html('Case1.2_wille.html')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create matrix of features and matrix of target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create matrix of features and matrix of target variable\n",
    "x = df.iloc[:, 0:13].values\n",
    "y = df.iloc[:, 13].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will make use of ScikitLearn’s ‘train_test_split’ function to divide our data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.84696501,  0.70272837, -0.17931043, ..., -0.97608981,\n",
       "        -0.73425926, -0.89074532],\n",
       "       [-1.62331451,  0.70272837,  0.8538592 , ...,  0.71115115,\n",
       "        -0.73425926,  1.11914156],\n",
       "       [-0.05776098, -1.42302495, -0.17931043, ..., -0.97608981,\n",
       "         0.32975715, -0.89074532],\n",
       "       ...,\n",
       "       [ 0.94866629, -1.42302495,  0.8538592 , ...,  0.71115115,\n",
       "         1.39377356, -0.89074532],\n",
       "       [ 0.27771478,  0.70272837,  0.8538592 , ..., -0.97608981,\n",
       "        -0.73425926,  1.11914156],\n",
       "       [ 1.06049155, -1.42302495,  0.8538592 , ...,  0.71115115,\n",
       "         1.39377356, -0.89074532]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.transform(x_test)\n",
    "x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting to built NN\n",
    "### Initializing Neural Network\n",
    "\n",
    "Our first parameter is output_dim. It is simply the number of nodes you want to add to this layer. \n",
    "init is the initialization of Stochastic Gradient Decent. In Neural Network we need to assign weights to each mode which is nothing but importance of that node. \n",
    "\n",
    "At the time of initialization, weights should be close to 0 and we will randomly initialize weights using uniform function. input_dim parameter is needed only for first layer as model doesn’t know the number of our input variables. \n",
    "As we knove the total number of input variables are 13. In the second layer model automatically knows the number of input variable from the first hidden layer.\n",
    "\n",
    "In upcoming code we recognize that syntax has changed during last few years. for example \"init\" is nowdays replaced with \"kernel_initializer\". There wasnt big problems with old syntax. while deployng code, it gave warnings, that the code is updated and replaced with....blaa blaa blaa,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the input layer and the first hidden layer\n",
    "#clasifier.add(Dense(output_dim = 6, init = 'uniform', activation = 'relu', input_dim = 13))            THESE ARE GIVING ERRORS\n",
    "clasifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu', input_dim = 13))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "#clasifier.add(Dense(output_dim = 6, init = 'uniform', activation = 'relu'))                             THESE ARE GIVING ERRORS\n",
    "clasifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "\n",
    "# Adding the output layer\n",
    "#clasifier.add(Dense(output_dim = 1, init = 'uniform', activation = 'sigmoid'))                           THESE ARE GIVING ERRORS\n",
    "clasifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid' ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling Neural Network\n",
    "\n",
    "First argument is Optimizer, this is nothing but the algorithm you wanna use to find optimal set of weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 6)                 84        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 6)                 42        \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 133\n",
      "Trainable params: 133\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Now here's the Deep Learning Neural Network model.\n",
    "clasifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "clasifier.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting our model\n",
    "Here we train our model\"classifier(typoed\"clasifier :D\")\" on training data but still one thing is remaining.\n",
    "Here we use fit method to the fit our model.\n",
    "Batch size is used to specify the number of observation after which you want to update weight. \n",
    "Epoch is nothing but the total number of iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6804 - acc: 0.5289\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 124us/step - loss: 0.6460 - acc: 0.5331\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 140us/step - loss: 0.5907 - acc: 0.5331\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 140us/step - loss: 0.4940 - acc: 0.5331\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 165us/step - loss: 0.3322 - acc: 0.5331\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 161us/step - loss: 0.0853 - acc: 0.5331\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 152us/step - loss: -0.2407 - acc: 0.5331\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 148us/step - loss: -0.6446 - acc: 0.5331\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 119us/step - loss: -1.1341 - acc: 0.5331\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 173us/step - loss: -1.7112 - acc: 0.5331\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 124us/step - loss: -2.4688 - acc: 0.5331\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 140us/step - loss: -3.3781 - acc: 0.5331\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 124us/step - loss: -4.2931 - acc: 0.5331\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 120us/step - loss: -4.9549 - acc: 0.5331\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 140us/step - loss: -5.3454 - acc: 0.5331\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 136us/step - loss: -5.6284 - acc: 0.5331\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 152us/step - loss: -5.8507 - acc: 0.5331\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 144us/step - loss: -6.0233 - acc: 0.5331\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 144us/step - loss: -6.1579 - acc: 0.5331\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 103us/step - loss: -6.2826 - acc: 0.5331\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 124us/step - loss: -6.3901 - acc: 0.5331\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 148us/step - loss: -6.4890 - acc: 0.5331\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 128us/step - loss: -6.5694 - acc: 0.5331\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 111us/step - loss: -6.6395 - acc: 0.5331\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 120us/step - loss: -6.7060 - acc: 0.5331\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 144us/step - loss: -6.7664 - acc: 0.5331\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 148us/step - loss: -6.8198 - acc: 0.5331\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 185us/step - loss: -6.8773 - acc: 0.5331\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 132us/step - loss: -6.9308 - acc: 0.5331\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 124us/step - loss: -6.9828 - acc: 0.5331\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 140us/step - loss: -7.0285 - acc: 0.5331\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 132us/step - loss: -7.0681 - acc: 0.5331\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 136us/step - loss: -7.1043 - acc: 0.5331\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 124us/step - loss: -7.1423 - acc: 0.5331\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 144us/step - loss: -7.1762 - acc: 0.5331\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 124us/step - loss: -7.2070 - acc: 0.5331\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 124us/step - loss: -7.2329 - acc: 0.5331\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 128us/step - loss: -7.2631 - acc: 0.5331\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 136us/step - loss: -7.2875 - acc: 0.5331\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 128us/step - loss: -7.3198 - acc: 0.5331\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 128us/step - loss: -7.3456 - acc: 0.5331\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 128us/step - loss: -7.3722 - acc: 0.5331\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 132us/step - loss: -7.3866 - acc: 0.5331\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 128us/step - loss: -7.3992 - acc: 0.5331\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 136us/step - loss: -7.4090 - acc: 0.5331\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 144us/step - loss: -7.4153 - acc: 0.5331\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 128us/step - loss: -7.4221 - acc: 0.5331\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 120us/step - loss: -7.4252 - acc: 0.5331\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 107us/step - loss: -7.4300 - acc: 0.5331\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 128us/step - loss: -7.4332 - acc: 0.5331\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 128us/step - loss: -7.4346 - acc: 0.5331\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 124us/step - loss: -7.4384 - acc: 0.5331\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 128us/step - loss: -7.4395 - acc: 0.5331\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 136us/step - loss: -7.4396 - acc: 0.5331\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 144us/step - loss: -7.4412 - acc: 0.5331\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 95us/step - loss: -7.4412 - acc: 0.5331\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 148us/step - loss: -7.4441 - acc: 0.5331\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 132us/step - loss: -7.4441 - acc: 0.5331\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 177us/step - loss: -7.4441 - acc: 0.5331\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 136us/step - loss: -7.4441 - acc: 0.5331\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 111us/step - loss: -7.4441 - acc: 0.5331\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 136us/step - loss: -7.4441 - acc: 0.5331\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 132us/step - loss: -7.4441 - acc: 0.5331\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 111us/step - loss: -7.4441 - acc: 0.5331\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 115us/step - loss: -7.4441 - acc: 0.5331\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 111us/step - loss: -7.4441 - acc: 0.5331\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 111us/step - loss: -7.4441 - acc: 0.5331\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 111us/step - loss: -7.4441 - acc: 0.5331\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 103us/step - loss: -7.4441 - acc: 0.5331\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 107us/step - loss: -7.4441 - acc: 0.5331\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 99us/step - loss: -7.4441 - acc: 0.5331\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 115us/step - loss: -7.4441 - acc: 0.5331\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 99us/step - loss: -7.4441 - acc: 0.5331\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 111us/step - loss: -7.4441 - acc: 0.5331\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 107us/step - loss: -7.4441 - acc: 0.5331\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 120us/step - loss: -7.4441 - acc: 0.5331\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 124us/step - loss: -7.4441 - acc: 0.5331\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 120us/step - loss: -7.4441 - acc: 0.5331\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 107us/step - loss: -7.4441 - acc: 0.5331\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 120us/step - loss: -7.4441 - acc: 0.5331\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 124us/step - loss: -7.4441 - acc: 0.5331\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 107us/step - loss: -7.4441 - acc: 0.5331\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 107us/step - loss: -7.4441 - acc: 0.5331\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 111us/step - loss: -7.4441 - acc: 0.5331\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 103us/step - loss: -7.4441 - acc: 0.5331\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 124us/step - loss: -7.4441 - acc: 0.5331\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 107us/step - loss: -7.4441 - acc: 0.5331\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 111us/step - loss: -7.4441 - acc: 0.5331\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 132us/step - loss: -7.4441 - acc: 0.5331\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 107us/step - loss: -7.4441 - acc: 0.5331\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 124us/step - loss: -7.4441 - acc: 0.5331\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 111us/step - loss: -7.4441 - acc: 0.5331\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 120us/step - loss: -7.4441 - acc: 0.5331\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 107us/step - loss: -7.4441 - acc: 0.5331\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 111us/step - loss: -7.4441 - acc: 0.5331\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 148us/step - loss: -7.4441 - acc: 0.5331\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 132us/step - loss: -7.4441 - acc: 0.5331\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 124us/step - loss: -7.4441 - acc: 0.5331\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 124us/step - loss: -7.4441 - acc: 0.5331\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 111us/step - loss: -7.4441 - acc: 0.5331\n",
      " \n",
      "Elapsed time: 3.85 seconds\n"
     ]
    }
   ],
   "source": [
    "# Fitting our model\n",
    "trainStart = time.time()\n",
    "clasifier.fit(x_train, y_train, epochs=100, batch_size=10)\n",
    "\n",
    "trainEnd = time.time()\n",
    "print(\" \")\n",
    "print('Elapsed time: {:.2f} seconds'.format(trainEnd - trainStart))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting the test set result. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = clasifier.predict(x_test)\n",
    "#y_pred = 1.0*(y_pred > 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is the final step where we are evaluating our model performance. \n",
    "We have original results and thus we can build confusion matrix to check the accuracy of model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-ff3201b3166e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Creating the Confusion Matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mcm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Case1.2_confusion_matrix.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mcm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight)\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m     \"\"\"\n\u001b[1;32m--> 253\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    254\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multiclass\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s is not supported\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[1;32m---> 81\u001b[1;33m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[1;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous targets"
     ]
    }
   ],
   "source": [
    "# Creating the Confusion Matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "df.to_csv('Case1.2_confusion_matrix.csv')\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So the Accuracy of our model can be calculated as:\n",
    "\n",
    "Accuracy= x + y / z =\n",
    "\n",
    "We'vv got % accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
